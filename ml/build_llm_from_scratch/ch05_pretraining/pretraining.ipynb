{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc25fdd5-3182-43ae-a1c5-0f867012eea9",
   "metadata": {},
   "source": [
    "# Chapter 5. Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bede521-94e0-46bc-8772-cd8ca18f09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2feb50bc-5c67-49ad-a649-8c0371230ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util.text_corpus()\n",
    "split_ratio = 0.8\n",
    "split_idx = int(len(data) * split_ratio)\n",
    "train_data, val_data = data[:split_idx], data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c236b6e-7d37-46d8-9367-30463ef8cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer: tiktoken.Encoding = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3122c963-9228-4af0-b3db-b8af37bc4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = util.Config.gpt2_small()\n",
    "torch.manual_seed(123)\n",
    "train_loader = util.create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    context_window=config.context_length,\n",
    "    stride=config.context_length,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "val_loader = util.create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    context_window=config.context_length,\n",
    "    stride=config.context_length,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc083f1c-f7c4-434e-9ee2-7121f9fda63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x: torch.Size([2, 1024]), y: torch.Size([2, 1024])\n",
      "train x: torch.Size([2, 1024]), y: torch.Size([2, 1024])\n",
      "val x: torch.Size([1, 1024]), y: torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(f'train x: {x.shape}, y: {y.shape}')\n",
    "for x, y in val_loader:\n",
    "    print(f'val x: {x.shape}, y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e4dd2db-72b2-4ecd-b775-efa647dc4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(\n",
    "    input_batch: torch.Tensor,\n",
    "    target_batch: torch.Tensor,\n",
    "    model: util.GPTModel,\n",
    "    device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e37747-0a28-4d88-bfcd-4c14a8f52c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS backend.\n"
     ]
    }
   ],
   "source": [
    "model = util.GPTModel(config)\n",
    "device: torch.device = util.auto_device()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9366dbd1-b95b-4cc5-b73e-8496db1eb36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.994\n",
      "Val loss: 11.013\n"
     ]
    }
   ],
   "source": [
    "def calc_loss_data_loader(\n",
    "    data_loader: DataLoader,\n",
    "    model: util.GPTModel,\n",
    "    device: torch.device,\n",
    "    num_batches: int | None = None,\n",
    ") -> float | None:\n",
    "    loss: float = 0\n",
    "    \n",
    "    if len(data_loader) <= 0:\n",
    "        return None\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (x, y) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss += calc_loss_batch(x, y, model, device).item()\n",
    "    return loss / num_batches\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(f'Train loss: {calc_loss_data_loader(train_loader, model, device):.3f}')\n",
    "    print(f'Val loss: {calc_loss_data_loader(val_loader, model, device):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cadf471-7b3b-4a6e-b2b1-22b901553e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: util.GPTModel,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    eval_iter: int,\n",
    ") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_data_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter,\n",
    "        )\n",
    "        val_loss = calc_loss_data_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter,\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(\n",
    "    model: util.GPTModel,\n",
    "    tokenizer: tiktoken.Encoding,\n",
    "    device: torch.device,\n",
    "    start_context: str,\n",
    "    max_len: int,\n",
    ") -> None:\n",
    "    generated = util.predict_text(model, device, tokenizer, start_context, max_len=max_len)\n",
    "    print(generated.replace('\\n', ' ')) # for easier reading\n",
    "\n",
    "def train_model_simple(\n",
    "    model: util.GPTModel,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    eval_freq: int,\n",
    "    eval_iter: int,\n",
    "    start_context: str,\n",
    "    tokenizer: tiktoken.Encoding\n",
    ") -> None:\n",
    "    train_losses: list[float] = []\n",
    "    val_losses: list[float] = []\n",
    "    track_tokens_seen: list[float] = []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(x, y, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += x.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f'Epoch {epoch + 1:03d} (step {global_step + 1:06d}): '\n",
    "                    f'train loss {train_loss:.3f}, val loss {val_loss:.3f}'\n",
    "                )\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context, max_len=8)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b48794-7e44-484d-ba51-cd374b5951c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 (step 000001): train loss 9.600, val loss 9.979\n",
      "Hello, ,,,,,,,,  , \n",
      "Epoch 002 (step 000003): train loss 8.652, val loss 9.074\n",
      "Hello, ,, the, the, the\n",
      "Epoch 003 (step 000005): train loss 7.734, val loss 8.464\n",
      "Hello, ,, the, the, the\n",
      "Epoch 004 (step 000007): train loss 6.776, val loss 7.976\n",
      "Hello, .     the    \n",
      "Epoch 005 (step 000009): train loss 6.253, val loss 7.751\n",
      "Hello, . the. Gisburn,\n",
      "Epoch 006 (step 000011): train loss 5.573, val loss 7.207\n",
      "Hello, .          \n",
      "Epoch 007 (step 000013): train loss 4.801, val loss 7.127\n",
      "Hello, . he was a. Gis\n",
      "Epoch 008 (step 000015): train loss 4.270, val loss 7.188\n",
      "Hello, . the. Gisburn's\n",
      "Epoch 009 (step 000017): train loss 3.774, val loss 7.142\n",
      "Hello, ,, I had been his pictures\n",
      "Epoch 010 (step 000019): train loss 3.332, val loss 7.045\n",
      "Hello, . . I the.  \n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq=2, eval_iter=5,\n",
    "    start_context=\"Hello, \", tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7aa6bc-f301-4216-a675-23e9200d219c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
