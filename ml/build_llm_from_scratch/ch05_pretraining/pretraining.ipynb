{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc25fdd5-3182-43ae-a1c5-0f867012eea9",
   "metadata": {},
   "source": [
    "# Chapter 5. Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bede521-94e0-46bc-8772-cd8ca18f09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2feb50bc-5c67-49ad-a649-8c0371230ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util.text_corpus()\n",
    "split_ratio = 0.8\n",
    "split_idx = int(len(data) * split_ratio)\n",
    "train_data, val_data = data[:split_idx], data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c236b6e-7d37-46d8-9367-30463ef8cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer: tiktoken.Encoding = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3122c963-9228-4af0-b3db-b8af37bc4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = util.Config.gpt2_xl()\n",
    "torch.manual_seed(123)\n",
    "train_loader = util.create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    context_window=config.context_length,\n",
    "    stride=config.context_length,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "val_loader = util.create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    context_window=config.context_length,\n",
    "    stride=config.context_length,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc083f1c-f7c4-434e-9ee2-7121f9fda63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train x: torch.Size([2, 1024]), y: torch.Size([2, 1024])\n",
      "train x: torch.Size([2, 1024]), y: torch.Size([2, 1024])\n",
      "val x: torch.Size([1, 1024]), y: torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(f'train x: {x.shape}, y: {y.shape}')\n",
    "for x, y in val_loader:\n",
    "    print(f'val x: {x.shape}, y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e4dd2db-72b2-4ecd-b775-efa647dc4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(\n",
    "    input_batch: torch.Tensor,\n",
    "    target_batch: torch.Tensor,\n",
    "    model: util.GPTModel,\n",
    "    device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e37747-0a28-4d88-bfcd-4c14a8f52c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA backend.\n"
     ]
    }
   ],
   "source": [
    "model = util.GPTModel(config)\n",
    "device: torch.device = util.auto_device()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9366dbd1-b95b-4cc5-b73e-8496db1eb36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.978\n",
      "Val loss: 10.976\n"
     ]
    }
   ],
   "source": [
    "def calc_loss_data_loader(\n",
    "    data_loader: DataLoader,\n",
    "    model: util.GPTModel,\n",
    "    device: torch.device,\n",
    "    num_batches: int | None = None,\n",
    ") -> float | None:\n",
    "    loss: float = 0\n",
    "    \n",
    "    if len(data_loader) <= 0:\n",
    "        return None\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (x, y) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss += calc_loss_batch(x, y, model, device).item()\n",
    "    return loss / num_batches\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(f'Train loss: {calc_loss_data_loader(train_loader, model, device):.3f}')\n",
    "    print(f'Val loss: {calc_loss_data_loader(val_loader, model, device):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cadf471-7b3b-4a6e-b2b1-22b901553e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: util.GPTModel,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    eval_iter: int,\n",
    ") -> tuple[float, float]:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_data_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter,\n",
    "        )\n",
    "        val_loss = calc_loss_data_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter,\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(\n",
    "    model: util.GPTModel,\n",
    "    tokenizer: tiktoken.Encoding,\n",
    "    device: torch.device,\n",
    "    start_context: str,\n",
    "    max_len: int,\n",
    ") -> None:\n",
    "    generated = util.predict_text(model, device, tokenizer, start_context, max_len=max_len)\n",
    "    print(generated.replace('\\n', ' ')) # for easier reading\n",
    "\n",
    "def train_model_simple(\n",
    "    model: util.GPTModel,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    eval_freq: int,\n",
    "    eval_iter: int,\n",
    "    start_context: str,\n",
    "    tokenizer: tiktoken.Encoding\n",
    ") -> None:\n",
    "    train_losses: list[float] = []\n",
    "    val_losses: list[float] = []\n",
    "    track_tokens_seen: list[float] = []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(x, y, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += x.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f'[{datetime.now().strftime(\"%H:%M:%S\")}] Epoch {epoch + 1:04d} (step {global_step + 1:06d}): '\n",
    "                    f'train loss {train_loss:.3f}, val loss {val_loss:.3f}'\n",
    "                )\n",
    "                generate_and_print_sample(model, tokenizer, device, start_context, max_len=8)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b48794-7e44-484d-ba51-cd374b5951c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:28:21] Epoch 0001 (step 000001): train loss 9.200, val loss 9.463\n",
      "He,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "[16:28:53] Epoch 0026 (step 000051): train loss 5.766, val loss 8.308\n",
      "He I, I I      \n",
      "[16:29:25] Epoch 0051 (step 000101): train loss 5.603, val loss 8.299\n",
      "He the of of of the of the of\n",
      "[16:29:56] Epoch 0076 (step 000151): train loss 4.586, val loss 8.696\n",
      "He't- was, and I I \"\n",
      "[16:30:28] Epoch 0101 (step 000201): train loss 2.846, val loss 10.248\n",
      "He\" life of of who, to his\n",
      "[16:31:00] Epoch 0126 (step 000251): train loss 0.891, val loss 11.717\n",
      "He\" widow Clauderaft Ver Ver widow\n",
      "[16:31:31] Epoch 0151 (step 000301): train loss 0.088, val loss 12.393\n",
      "He\t liked Claudeanielive ad existedrees\n",
      "[16:32:03] Epoch 0176 (step 000351): train loss 0.041, val loss 12.635\n",
      "He\t liked Claude Claude Ver women left\t\n",
      "[16:32:35] Epoch 0201 (step 000401): train loss 0.008, val loss 12.800\n",
      "He of discussion only first prism, on any\n",
      "[16:33:07] Epoch 0226 (step 000451): train loss 0.006, val loss 12.801\n",
      "He of discussion life \" if \"Gr in\n",
      "[16:33:39] Epoch 0251 (step 000501): train loss 0.003, val loss 12.768\n",
      "He of discussion life \" loss surprise weeks always\n",
      "[16:34:10] Epoch 0276 (step 000551): train loss 0.002, val loss 12.936\n",
      "He of prism Gideon \" loss balance years-\n",
      "[16:34:42] Epoch 0301 (step 000601): train loss 0.002, val loss 12.823\n",
      "He of discussion itself height he wason-\n",
      "[16:35:14] Epoch 0326 (step 000651): train loss 0.001, val loss 13.037\n",
      "He height height height of art height frame with\n",
      "[16:35:46] Epoch 0351 (step 000701): train loss 0.002, val loss 12.875\n",
      "He ofley of Mrs ensuingoring he was\n",
      "[16:36:18] Epoch 0376 (step 000751): train loss 0.001, val loss 12.817\n",
      "He height ( Ar I was women_ those\n",
      "[16:36:50] Epoch 0401 (step 000801): train loss 0.001, val loss 12.803\n",
      "He height height height of artoring display resolve\n",
      "[16:37:21] Epoch 0426 (step 000851): train loss 0.001, val loss 12.937\n",
      "He height height heightrees height Ar who appeared\n",
      "[16:37:53] Epoch 0451 (step 000901): train loss 0.001, val loss 12.942\n",
      "He height be height I surprise women-breeding\n",
      "[16:38:25] Epoch 0476 (step 000951): train loss 0.001, val loss 12.744\n",
      "He frame appeared (_ I was women heard (\n",
      "[16:38:57] Epoch 0501 (step 001001): train loss 0.002, val loss 12.895\n",
      "He frame's  _ seen simplyd\n",
      "[16:39:29] Epoch 0526 (step 001051): train loss 0.037, val loss 12.361\n",
      "He frame beOhoms slightly (_ of Mrs\n",
      "[16:40:01] Epoch 0551 (step 001101): train loss 0.002, val loss 12.769\n",
      "He frame height Ver always women women   Jack\n",
      "[16:40:32] Epoch 0576 (step 001151): train loss 0.001, val loss 12.656\n",
      "He height height Iisburn appeared- It\n",
      "[16:41:04] Epoch 0601 (step 001201): train loss 0.002, val loss 12.781\n",
      "He height height height appearance ensuing Gisburn\n",
      "[16:41:36] Epoch 0626 (step 001251): train loss 0.000, val loss 12.810\n",
      "He such latter think Gisburn appearedugal\n",
      "[16:42:08] Epoch 0651 (step 001301): train loss 0.001, val loss 12.906\n",
      "He frame be what of beautyoring leftively\n",
      "[16:42:40] Epoch 0676 (step 001351): train loss 0.000, val loss 12.855\n",
      "He wonder. To Ar years between have heard\n",
      "[16:43:11] Epoch 0701 (step 001401): train loss 0.000, val loss 12.750\n",
      "He height women wonder_ between Gisburn\n",
      "[16:43:43] Epoch 0726 (step 001451): train loss 0.001, val loss 12.660\n",
      "He frame between; and untouched because prism exquisite\n",
      "[16:44:15] Epoch 0751 (step 001501): train loss 0.001, val loss 12.739\n",
      "He frame height   It Jack height weeksit\n",
      "[16:44:47] Epoch 0776 (step 001551): train loss 0.001, val loss 13.103\n",
      "He frame exquisite what height   women   think\n",
      "[16:45:19] Epoch 0801 (step 001601): train loss 0.000, val loss 12.924\n",
      "He such ( I always left For resolve\n",
      "[16:45:50] Epoch 0826 (step 001651): train loss 0.000, val loss 12.875\n",
      "He heightburn! ensuing   women wonder!\n",
      "[16:46:22] Epoch 0851 (step 001701): train loss 0.001, val loss 12.855\n",
      "He frame   It be Jack; aside height\n",
      "[16:46:54] Epoch 0876 (step 001751): train loss 0.000, val loss 12.745\n",
      "He frame   It be been Gisburn\n",
      "[16:47:26] Epoch 0901 (step 001801): train loss 0.004, val loss 13.006\n",
      "He frame   It be Jack Gisburn\n",
      "[16:47:58] Epoch 0926 (step 001851): train loss 0.002, val loss 12.968\n",
      "He frame   It was Jack see heard Ver\n",
      "[16:48:30] Epoch 0951 (step 001901): train loss 0.001, val loss 12.707\n",
      "He frame at Gisburn Jack so.\"\n",
      "[16:49:01] Epoch 0976 (step 001951): train loss 0.000, val loss 12.721\n",
      "Heial. And and couldn felt suchwhat\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "num_epochs = 1_000\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq=50, eval_iter=1,\n",
    "    start_context=\"He\", tokenizer=tokenizer,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
