{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aac016e-d730-4100-8d4b-e04e734de03d",
   "metadata": {},
   "source": [
    "# Chapter 3: Coding attention mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8aad1b-6247-43f3-9f39-af5278183f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ae5fc-1963-459c-a696-f170f8cd6575",
   "metadata": {},
   "source": [
    "## 1. Simplified self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f95d69-ceee-496f-8526-0b45ec2f264c",
   "metadata": {},
   "source": [
    "### Create embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d994da5a-995b-4b2e-9e3c-6577a823fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos = '<|endoftext|>'\n",
    "text = \"Your journey starts with one step\" + eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb42f076-efe3-4c3d-ab16-ba649af8c3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7120,  7002,  4940,   351,   530,  2239, 50256])\n"
     ]
    }
   ],
   "source": [
    "data_loader = util.create_dataloader_v1(\n",
    "    text,\n",
    "    batch_size=1,\n",
    "    context_window=6,\n",
    "    stride=7,\n",
    ")\n",
    "data_iter = iter(data_loader)\n",
    "x, y = next(data_iter)\n",
    "# Need to concat from the last element of the target tensor,\n",
    "# otherwise, setting context window as 4 results in a crash.\n",
    "token_ids = torch.cat((x[0], y[0, -1:]))\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee72dd75-2663-4baa-86e8-289af42f0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_len: int = token_ids.size(0)\n",
    "vocab_size: int = torch.max(token_ids).item() + 1\n",
    "embed_dim: int = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "484ea74a-c673-4e1e-a12b-709e43209c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8311,  1.3393, -1.1653],\n",
      "        [-0.9936,  0.8519, -2.3310],\n",
      "        [ 2.2730,  1.0514, -0.6150],\n",
      "        [ 1.2780, -0.2958, -1.4757],\n",
      "        [-2.9027,  3.0901,  0.6925],\n",
      "        [-0.7583,  0.3646, -0.9988],\n",
      "        [-2.1264,  0.5579, -1.1521]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "tok_embed_layer = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "pos_embed_layer = torch.nn.Embedding(tokens_len, embed_dim)\n",
    "inputs = tok_embed_layer(token_ids) + pos_embed_layer(torch.arange(tokens_len))\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec285b-303f-4adb-8849-ec580c51f5d1",
   "metadata": {},
   "source": [
    "### Attention Weight (for \"journey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcae133-b256-45b4-a3c0-d3e4502b2c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights:\n",
      "tensor([0.0130, 0.8070, 0.0010, 0.0040, 0.0310, 0.0190, 0.1240],\n",
      "       grad_fn=<RoundBackward1>)\n",
      "Sum: tensor(1., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(tokens_len)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=-1)\n",
    "print(\"Attention weights:\")\n",
    "print(torch.round(attn_weights_2, decimals=3))\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b0df4-cd6a-4cae-9bfe-4ee26d95f9f5",
   "metadata": {},
   "source": [
    "### Attention weight (for all inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3805f301-0e3b-42e0-8b44-a313ecc819d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights:\n",
      "tensor([[0.3320, 0.1480, 0.3950, 0.0770, 0.0180, 0.0200, 0.0100],\n",
      "        [0.0130, 0.8070, 0.0010, 0.0040, 0.0310, 0.0190, 0.1240],\n",
      "        [0.0640, 0.0010, 0.8960, 0.0380, 0.0000, 0.0010, 0.0000],\n",
      "        [0.1070, 0.0670, 0.3250, 0.4840, 0.0000, 0.0150, 0.0030],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [0.0380, 0.4050, 0.0070, 0.0200, 0.1900, 0.0750, 0.2650],\n",
      "        [0.0010, 0.1030, 0.0000, 0.0000, 0.6370, 0.0100, 0.2490]],\n",
      "       grad_fn=<RoundBackward1>)\n",
      "Sum: tensor(7.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(\"Attention weights:\")\n",
    "print(torch.round(attn_weights, decimals=3))\n",
    "print(\"Sum:\", attn_weights.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff568fde-95b5-4e57-b79f-f44d3093ee47",
   "metadata": {},
   "source": [
    "### Context vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a0c8a1-f71f-4e87-9fa9-0452b24cb603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors:\n",
      "tensor([[ 1.0378,  1.0312, -1.1078],\n",
      "        [-1.1537,  0.8782, -2.0441],\n",
      "        [ 2.1363,  1.0175, -0.6857],\n",
      "        [ 1.3623,  0.4056, -1.2118],\n",
      "        [-2.9026,  3.0900,  0.6925],\n",
      "        [-1.5024,  1.1598, -1.2709],\n",
      "        [-2.4877,  2.1992, -0.0969]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "context_vectors = attn_weights @ inputs\n",
    "print(\"Context vectors:\")\n",
    "print(context_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13eb5c-377e-4ade-a425-f4b85e4d7b9d",
   "metadata": {},
   "source": [
    "## 2. Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03930ec-50ed-4962-a194-026bc90e7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91aad08d-dddf-474a-8fae-4558b0b7dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "519916af-1433-4b2e-ad61-f6b0a4216a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0809, -0.4605], grad_fn=<SqueezeBackward4>)\n",
      "tensor([-1.2738, -1.7953], grad_fn=<SqueezeBackward4>)\n",
      "tensor([-0.8775, -1.3379], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)\n",
    "print(key_2)\n",
    "print(value_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b583220e-7538-4163-badd-3b41d8b6ab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([7, 2])\n",
      "values.shape: torch.Size([7, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(f'keys.shape: {keys.shape}')\n",
    "print(f'values.shape: {values.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dfccc20-3e8e-424d-9c89-03c6701f23e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2034785747528076\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "attn_score_2_2 = query_2.dot(keys_2)\n",
    "print(attn_score_2_2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9521acf4-3953-4381-b0af-f9e51b6d47fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5480,  2.2035, -2.2023, -0.1176,  1.1066,  1.2662,  2.6174],\n",
      "       grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d2f014-9a17-4039-b542-b39b9bc0a6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.0387, 0.2705, 0.0120, 0.0524, 0.1245, 0.1394, 0.3625],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Attention weights sum: 0.9999999403953552\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2 / keys.shape[-1] ** 0.5, dim=-1)\n",
    "print(f'Attention weights: {attn_weights_2}')\n",
    "print(f'Attention weights sum: {attn_weights_2.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cec4b7f-e5b7-4d1f-b5bb-2769f6651d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7672, -1.1645], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09137b93-eb25-40cf-8ef9-eba043a30bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
