{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cc80255-68eb-4aeb-a679-e6ef567d9182",
   "metadata": {},
   "source": [
    "# Chapter 2. Working with Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b569f11-32b1-44f6-b353-0efae7618f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import util\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812be28-9ff6-4994-99b9-2f7faa759ecf",
   "metadata": {},
   "source": [
    "## Encoder Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3c00e9-d5df-4b4b-a3db-f7cda8764b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = util.text_corpus()\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a652e58-b4ab-4098-b032-d2f754375ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = \"Hello<|endoftext|> > !!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc4da9f-e629-4186-a372-37d171863647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 50256, 1875, 220, 10185]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode(text_test, allowed_special={'<|endoftext|>'})\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda91d2-e6f3-4fd3-8722-8096f5e51a9e",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59496cd3-94ff-4d25-bb59-363737f36357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    _input_ids: list[torch.Tensor]\n",
    "    _target_ids: list[torch.Tensor]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        content: str,\n",
    "        tokenizer: tiktoken.core.Encoding,\n",
    "        context_window_size: int,\n",
    "        stride: int\n",
    "    ):\n",
    "        self._input_ids = []\n",
    "        self._target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(content)\n",
    "\n",
    "        for i in range(0, len(token_ids) - context_window_size, stride):\n",
    "            input_chunk = token_ids[i:i + context_window_size]\n",
    "            target_chunk = token_ids[i + 1: i + 1 + context_window_size]\n",
    "            self._input_ids.append(torch.tensor(input_chunk))\n",
    "            self._target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._input_ids)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> (torch.Tensor, torch.Tensor):\n",
    "        return self._input_ids[idx], self._target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b37b599-85cd-45de-9247-2be7cbf4b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(\n",
    "    content: str,\n",
    "    batch_size: int,\n",
    "    context_window: int, \n",
    "    stride: int = 1,\n",
    "    shuffle: bool = True,\n",
    "    drop_last: bool = True,\n",
    "    num_workers: int = 0,\n",
    ") -> DataLoader:\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    dataset = GPTDatasetV1(content, tokenizer, context_window, stride)\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3aa14e2-f3c6-427d-8a92-2671d56491dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_window_size = 256\n",
    "data_loader = create_dataloader_v1(text, batch_size=8, context_window=context_window_size, stride=128)\n",
    "data_iter = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb08861-5f79-44e3-a408-1323d5fed633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1555,   262,  1306,  ...,  6846,    11,   314],\n",
       "         [ 1276,   751,    11,  ...,   198,     1,  3666],\n",
       "         [ 1422,   470,   438,  ...,   271, 10899,   550],\n",
       "         ...,\n",
       "         [ 4562,    11,  3181,  ...,   673,   550,   407],\n",
       "         [   12, 12239,    11,  ...,   965,  1397,    11],\n",
       "         [12917,   905,    11,  ...,   550,  1813,   510]]),\n",
       " tensor([[  262,  1306,  1110,  ...,    11,   314,  1276],\n",
       "         [  751,    11,   339,  ...,     1,  3666, 13674],\n",
       "         [  470,   438,    83,  ..., 10899,   550,   257],\n",
       "         ...,\n",
       "         [   11,  3181,   503,  ...,   550,   407, 17901],\n",
       "         [12239,    11,   475,  ...,  1397,    11,   326],\n",
       "         [  905,    11,  5025,  ...,  1813,   510,   465]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7755af24-bdc1-48c4-ae2f-345e889f9694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([8, 256]), torch.Size([8, 256]))\n"
     ]
    }
   ],
   "source": [
    "x, y = next(data_iter)\n",
    "print((x.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933094f-296e-4756-9856-02dfe83bb27e",
   "metadata": {},
   "source": [
    "## Embedding Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b787b6-5e89-4d54-b7ec-e5d7ad59a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_vocab_size: int = 6\n",
    "demo_output_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e1a5916-bbe3-468c-bf3a-13c42a7ebd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5471, -0.2956,  0.1631],\n",
      "        [-0.8480,  1.5287,  0.1057],\n",
      "        [-0.1845, -0.1617,  1.1812],\n",
      "        [-0.5664,  1.1810, -0.2273],\n",
      "        [-1.4231, -0.3947,  1.6258],\n",
      "        [-0.6573,  1.3287,  1.8565]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "demo_embedding_layer = torch.nn.Embedding(demo_vocab_size, demo_output_dim)\n",
    "print(demo_embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e904a615-9183-4fde-a675-ced7aef6ec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5471, -0.2956,  0.1631],\n",
       "        [-0.1845, -0.1617,  1.1812],\n",
       "        [-0.5664,  1.1810, -0.2273]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result should be a simple lookup.\n",
    "demo_embedding_layer(torch.tensor([0, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f2df42-4fc5-4d68-8ed9-09f3d283cffb",
   "metadata": {},
   "source": [
    "## Token Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33fe306c-1f54-4c89-9e21-bc7829470b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.max_token_value + 1\n",
    "output_dim = 512\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb9fac24-8752-4ac4-a8cf-4eabf8c07657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x_embedding = token_embedding_layer(next(data_iter)[0])\n",
    "batch_x_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fd3e7-9ed4-411e-9a23-9dff009017db",
   "metadata": {},
   "source": [
    "## Position Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bacd56a-a787-432a-a095-95708aa5b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embedding_layer = torch.nn.Embedding(context_window_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a4d99d3-523f-478a-91cd-3b12c74b911b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_position_embedding = position_embedding_layer(torch.arange(context_window_size).unsqueeze(0))\n",
    "batch_position_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36dbe41-e08e-4ba3-868d-b68276ae2add",
   "metadata": {},
   "source": [
    "## Combine Token and Position Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bb66451-9d92-4a49-bbb3-111861f1ab5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding = batch_x_embedding + batch_position_embedding\n",
    "input_embedding.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
