{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b569f11-32b1-44f6-b353-0efae7618f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import util\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3c00e9-d5df-4b4b-a3db-f7cda8764b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = util.text_corpus()\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378e73eb-411e-43a1-9cc4-16859286dfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tiktoken.core.Encoding'>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a652e58-b4ab-4098-b032-d2f754375ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = \"Hello<|endoftext|> > !!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc4da9f-e629-4186-a372-37d171863647",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(text_test, allowed_special={'<|endoftext|>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59496cd3-94ff-4d25-bb59-363737f36357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    _input_ids: list[torch.Tensor]\n",
    "    _target_ids: list[torch.Tensor]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        content: str,\n",
    "        tokenizer: tiktoken.core.Encoding,\n",
    "        context_window_size: int,\n",
    "        stride: int\n",
    "    ):\n",
    "        self._input_ids = []\n",
    "        self._target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(content)\n",
    "\n",
    "        for i in range(0, len(token_ids) - context_window_size, stride):\n",
    "            input_chunk = token_ids[i:i + context_window_size]\n",
    "            target_chunk = token_ids[i + 1: i + 1 + context_window_size]\n",
    "            self._input_ids.append(torch.tensor(input_chunk))\n",
    "            self._target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._input_ids)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> (torch.Tensor, torch.Tensor):\n",
    "        return self._input_ids[idx], self._target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b37b599-85cd-45de-9247-2be7cbf4b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(\n",
    "    content: str,\n",
    "    batch_size: int,\n",
    "    context_window: int, \n",
    "    stride: int = 1,\n",
    "    shuffle: bool = True,\n",
    "    drop_last: bool = True,\n",
    "    num_workers: int = os.cpu_count(),\n",
    ") -> DataLoader:\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "    dataset = GPTDatasetV1(content, tokenizer, context_window, stride)\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3aa14e2-f3c6-427d-8a92-2671d56491dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = create_dataloader_v1(text, batch_size=8, context_window=256, stride=128)\n",
    "data_iter = iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb08861-5f79-44e3-a408-1323d5fed633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[12917,   905,    11,  ...,   550,  1813,   510],\n",
       "         [  526,   198,   198,  ...,    13,  1320,   338],\n",
       "         [16153,   312,   328,  ...,  2982,   257,  2366],\n",
       "         ...,\n",
       "         [  550,  1908,   477,  ...,    11,   290,  3088],\n",
       "         [  628,   198,   198,  ..., 22988,   198,   198],\n",
       "         [  617,   286,   616,  ...,   616,  1243,    30]]),\n",
       " tensor([[  905,    11,  5025,  ...,  1813,   510,   465],\n",
       "         [  198,   198,     1,  ...,  1320,   338,   262],\n",
       "         [  312,   328,  3780,  ...,   257,  2366,  9662],\n",
       "         ...,\n",
       "         [ 1908,   477,   616,  ...,   290,  3088,   617],\n",
       "         [  198,   198,  8585,  ...,   198,   198,    35],\n",
       "         [  286,   616, 49025,  ...,  1243,    30,  1119]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7755af24-bdc1-48c4-ae2f-345e889f9694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([8, 256]), torch.Size([8, 256]))\n"
     ]
    }
   ],
   "source": [
    "x, y = next(data_iter)\n",
    "print((x.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b787b6-5e89-4d54-b7ec-e5d7ad59a81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
